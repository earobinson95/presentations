---
title: "HUMAN PERCEPTION OF EXPONENTIALLY INCREASING DATA DISPLAYED ON A LOG SCALE EVALUATED THROUGH EXPERIMENTAL GRAPHICS TASKS"
subtitle: "Ph.D. Final Examination"
author: "Emily Robinson"
date: "Department of Statistics, University of Nebraska - Lincoln"
output:
  xaringan::moon_reader:
    seal: false
    includes:
      after_body:
        "js-addins.html"
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: ["default", "metropolis-fonts", "metropolis" ,"css/modal.css", "css/sizeformat.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightlines: true
      countIncrementalSlides: true
---
class:title-slide-custom

```{r, child = "style.Rmd"}
```


```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
# Packages
library(emoji)
library(purrr)
library(tidyverse)
library(gridExtra)
library(nullabor)
library(scales)
library(knitr)
library(kableExtra)
library(RefManageR)
library(iconr)
library(fontawesome)
library(shiny)
# download_fontawesome()

# References
bib <- ReadBib("bib/thesis.bib", check = FALSE)
ui <- "- "

# R markdown options
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE, 
                      warning = FALSE, 
                      cache = TRUE,
                      dpi = 300)
options(htmltools.dir.version = FALSE)
options(knitr.kable.NA = '')
```

```{r, include = F, eval = T, cache = T}
clean_file_name <- function(x) {
  basename(x) %>% str_remove("\\..*?$") %>% str_remove_all("[^[A-z0-9_]]")
}
img_modal <- function(src, alt = "", id = clean_file_name(src), other = "") {
  
  other_arg <- paste0("'", as.character(other), "'") %>%
    paste(names(other), ., sep = "=") %>%
    paste(collapse = " ")
  
  js <- glue::glue("<script>
        /* Get the modal*/
          var modal{id} = document.getElementById('modal{id}');
        /* Get the image and insert it inside the modal - use its 'alt' text as a caption*/
          var img{id} = document.getElementById('img{id}');
          var modalImg{id} = document.getElementById('imgmodal{id}');
          var captionText{id} = document.getElementById('caption{id}');
          img{id}.onclick = function(){{
            modal{id}.style.display = 'block';
            modalImg{id}.src = this.src;
            captionText{id}.innerHTML = this.alt;
          }}
          /* When the user clicks on the modalImg, close it*/
          modalImg{id}.onclick = function() {{
            modal{id}.style.display = 'none';
          }}
</script>")
  
  html <- glue::glue(
     " <!-- Trigger the Modal -->
<img id='img{id}' src='{src}' alt='{alt}' {other_arg}>
<!-- The Modal -->
<div id='modal{id}' class='modal'>
  <!-- Modal Content (The Image) -->
  <img class='modal-content' id='imgmodal{id}'>
  <!-- Modal Caption (Image Text) -->
  <div id='caption{id}' class='modal-caption'></div>
</div>
"
  )
  write(js, file = "js-addins.html", append = T)
  return(html)
}
# Clean the file out at the start of the compilation
write("", file = "js-addins.html")
```

<br><br><br>
## Human Perception of Exponentially Increasing Data Displayed on a Log Scale Evaluated Through Experimental Graphics Tasks
### Ph.D. Final Exmaination
#### Emily A. Robinson
#### Department of Statistics, University of Nebraska - Lincoln
<!-- ##### `r fa("envelope", fill = "black")` [emily.robinson@huskers.unl.edu](emily.robinson@huskers.unl.edu) -->
<!-- ##### `r fa("home", fill = "black")` [www.emilyarobinson.com](https://www.emilyarobinson.com/) -->
<!-- ##### `r fa("github", fill = "black")` [earobinson95](https://github.com/earobinson95) -->
<!-- <br><br> -->
<!-- .medium[*Slides: https://bit.ly/3ENZmOZ*] -->

???

Thank you to everyone who is attending this morning both in person and online. I will be sharing my Ph.D. work on the human perception of exponentially increasing data displayed on a log scale evaluated through experimental graphics tasks.

---
class:primary
# Outline

`r fa_i("chart-bar")` Motivation and Background

`r fa_i("list")` Research Objectives

`r fa_i("chart-line")` Perception through Lineups

`r fa_i("pen")` Prediction with 'You Draw It'

`r fa_i("ruler")` Numerical Translation and Estimation

`r fa_i("check-double")` Overall conclusion

`r fa_i("spinner")` Future Work

???

I will first start with the motivation and background of this work and I will introduce the research objectives. Next, I will give a high level overview of the two studies related to perception and prediction as I have previously shared work related to these two chapters. Then I will discuss the development and results from the last study as it relates to estimation and graph comprehension. Lastly, I will provide an overall conclusion and discuss future directions for this work.

---
class:inverse
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
.center[
# Motivation and Background
]

---
class:primary
# Motivation

Data visualizations played an important role in during the **COVID-19 pandemic** `r Citep(bib[[c("rost_2020", "romano_scale_2020", "bavel_using_2020")]])`.

Dashboards displayed: case counts, transmission rates, outbreak regions. 

.center[
```{r, out.width = "75%"}
knitr::include_graphics("images/91divoc-cases-july2021.png")
```

`r Citep(bib[[c("fagen-ulmschneider_2020")]])`
]

???

The motivation for this work came from the large impact graphics and charts have had during the COVID-19 pandemic. Many of these graphics helped guide decision makers to implement policies such as shut-downs or mandated mask wearing, as well as facilitated communication with the public to increase compliance. 

As graphics began to play an important role in sharing information with the public, it was crucial to start asking what made some of these charts better than others? Creators of the graphics were faced with many design choices in order to ensure their charts were effective at accurately communicating the current status of the pandemic.

In order to make educated decisions when designing a chart, we need to establish guidelines through experimentation in order to ensure the graphic is effective at communicating the intended results.

---
class:primary
# Graphics: the 'good' and the 'bad'

.pull-left[
**Misleading Graphics**
+ Bad Form
+ "Chartjunk"
+ Bad axes

**Graphical Guidelines** 
`r Citep(bib[[c("wickham2013graphical", "andrews_2022")]])`
+ Keep symbols to a minimum; `r Citep(bib[[c("tufte1985visual")]])` coins the term “chartjunk”.
+ Use of lengths over areas or volumes. `r Citep(bib[[c("cleveland1987graphical")]])`
+ Proper use of scales such as arrangements, labels, and baselines.
].pull-right[

```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/misleading-graphics-bad-form-supercomputers.png", alt = Citep(bib[[c("dongarra1997top500")]]), other=list(width="45%"))
i2 <- img_modal(src = "images/misleading-graphics-bad-axes-rouble-to-dollar.jpg", alt = Citep(bib[[c("villa_2022")]]), other=list(width="45%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i2, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9],
  str_split(i2, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```

```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/standards-of-graphics-log-scale.jpg", alt = Citep(bib[[c("andrews_2022")]]), other=list(width="100%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```

]
???

In order to ensure your chart is effective, it is important to first understand the many ways in which plots may inaccurately display the data and be ineffective or misleading in sharing information and results. A few ways a chart may be ineffective are by selecting bad form (such as a 3D pie chart), including too much clutter or chartjunk, or by selecting bad axes. This might be by the baseline selected, as shown here, which changes the perceptual interpretation of the chart or by the scale selected to be used on the axes.

Recommendations and guidelines emerged in the early 1900s to help improve the overall quality of graphics. Wickham (2013) gives a review and critique of the first formal advice for creating good graphics presented by The International Institute of Statistics in 1901. Andrews (2022) recalls seventeen general suggestions for the visualization of statistical and quantitative data published by The American Society of Mechanical Engineers (ASME) in 1915. What is interesting about some of these guidelines, is that even though they were stated in the early 20th century, it took, in some cases, over 100 years to establish and ground these guiding principles through experimentation. A few recommendations made include to keep the symbols to a minimum (avoiding chartjunk), using lengths over areas over volumes (we all may have previously heard that bar charts are better than pie charts), and use proper scales. Here, the ASME advocated for careful consideration of the limiting lines for curves drawn on logarithmic coordinates. I also want to draw your attention to the minor grid line breaks here drawn at 2 million, 3 million, 4 million, etc. but since they are displayed on the log scale, they visually appear unequal in spacial distance although they are equally spaced numerically.

---
class:primary
# Testing statistical graphics

Evaluate design choices and understand cognitive biases through the use of visual tests `r Citep(bib[[c("cleveland_graphical_1984", "lewandowsky_perception_1989", "spence_visual_1990", "vanderplas_testing_2020")]])`.

Could ask participants to:

- identify differences in graphs.
- read information off of a chart accurately.
- use data to make correct real-world decisions.
- predict the next few observations.

All of these types of tests require different levels of use and manipulation of the information presented in the chart.

???

One way in which we establish guidelines is through the use of graphical testing methods. This allows researchers to conduct studies geared at understanding human ability to conduct tasks related to the perception of statistical charts. These tests may take many forms such as identifying differences in graphs, accurately reading information off a chart, using data to make correct real-world decisions, or predicting the next few observations. All of these types of tests require different levels of use and manipulation of the information presented in the chart.

---
class:primary
# Logarithmic scales

.center[
```{r, out.width = "90%"}
knitr::include_graphics("images/log-scales-1.png")
```
]

???

A major issue we encountered in the creation of COVID-19 plots was how to display data from a wide range of values.

+ **Problem:** Data which spans several orders of magnitude shown on its original scale compresses the smaller magnitudes into relatively little area.
+ **Solution:** Use of a log scale transformation; alters the contextual appearance of the data.

---
class:primary
# Benefits and pitfalls of log scales

.pull-left[

**Benefits** were seen in spring 2020, during the early stages of the COVID-19 pandemic.
.center[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/covid19-FT-03.23.2020-log.png", alt = Citep(bib[[c("burnmurdoch_2020")]]), other=list(width="100%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]

].pull-right[

**Pitfalls** were exposed as the pandemic evolved, and the case counts were no longer spreading exponentially. 

.center[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/covid19-FT-linear.png", alt = Citep(bib[[c("burnmurdoch_2020")]]), other=list(width="80%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```

```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/covid19-FT-log.png", alt = Citep(bib[[c("burnmurdoch_2020")]]), other=list(width="80%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]
]

**Benefits** were seen in spring 2020, during the early stages of the COVID-19 pandemic.

+ Large magnitude discrepancies in case counts at a given time point between different geographic regions.
+ Log scale transformations were usefulness for showing case count curves for areas with few cases and areas with many cases within one chart.

**Pitfalls** were exposed as the pandemic evolved, and the case counts were no longer spreading exponentially.

+ Graphs with linear scales seemed more effective at spotting early increases in case counts that signaled more localized outbreaks.
+ The effect of the linear scale appears to evoke a stronger reaction from the public than the log scale.

While this is one such example, there is a long history of using log scales to display results in ecology, psychophysics, engineering, and physics. Given the widespread use of logarithmic scales, it is important to understand the implications of their use in order to provide guidelines for best use.

---
class:primary
# Logarithmic mapping

Our perception is **logarithmic at first**, but transitions to a **linear scale later** in development `r Citep(bib[[c("dehaene2008log", "siegler_numerical_2017", "varshney_why_2013")]])`.

.center[
```{r, out.width = "80%"}
knitr::include_graphics("images/log-number-line-1.png")
```
]

**Assumption:** If we perceive logarithmically by default, it is a natural way to display information and should be easy to read and understand/use.

???

When we first learn to count, we begin counting by ones, then by tens, and advancing to hundreds, following the base10 order of magnitude system.

Research shows our perception and mapping of numbers to a number line is **logarithmic at first**, but transitions to a **linear scale later** in development, with formal mathematics education.
+ For example: A kindergartner asked to place numbers one through ten along a number line would place three close to the middle, following the logarithmic perspective.

Regardless of training, we also know our visual system is vulnerable to biases related to different stimuli such as weight, light, or sound. Weber's law established that we do not notice absolute changes in stimuli, but instead, we notice the relative change. For example, if the volume of a speaker is set quiet and you turn it up slightly, you are going to think the change was large compared to if the volume of the speaker was already blasting and you turned it up the same amount as when it was quiet. The Weber-Fechner law extended this discovery and stated that the relationship between the perceived intensity (as sensed by the person) is logarithmic to the stimulus intensity (as outputted by the object source) when observed above a minimal threshold of perception.

Assuming there is a direct relationship between perceptual and cognitive processes, it is reasonable to assume numerical representations should also be displayed on a nonlinear, compressed number scale. Therefore, if we perceive logarithmically by default, it is a natural (and presumably low effort) way to display information and should be easy to read and understand/use.

---
class:primary
# Exponential growth
.center[
```{r, out.width = "65%"}
knitr::include_graphics("images/exponential-stages-comic.jpg")
```

`r Citep(bib[[c("vonbergmann_2021")]])`
]

Estimation and prediction of **exponential growth is underestimated** when presented both numerically and graphically `r Citep(bib[[c("jones_generalized_1979", "mackinnon_feedback_1991", "wagenaar_misperception_1975")]])`.

???

In addition to biases which result from the use of log scales, there is a general misinterpretation of exponential growth. This visual illustrates how individuals in public health interpret exponential growth distincly different from scientists during early, middle, and late stages of growth. 

Early studies explored the estimation and prediction of exponential growth and found that *growth is underestimated** when presented both numerically and graphically `r Citep(bib[[c("jones_generalized_1979", "mackinnon_feedback_1991", "wagenaar_misperception_1975")]])`.

**Can log transforming the data help?**

+ Maybe, but are there consequences? 
+ Most readers are not mathematically sophisticated enough to intuitively understand logarithmic math and translate that back into real-world effects.

---
class:inverse
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
.center[
# Comprehensive graphical studies
]

???
In this section, we will take a look at how different graphical tasks are related to different levels of cognition and how that relates to my research objectives.

---
class:primary
# Task complexity

`r Citep(bib[[c("carpenter1998model")]])` identifies pattern recognition, interpretative processes, and integrative processes as strategies and processes required to complete tasks of varying degrees of complexity. 

+ **Pattern recognition** requires the viewer to encode graphic patterns.

+ **Interpretive processes** operate on those patterns to construct meaning.

+ **Integrative processes** then relate the meanings to the contextual scenario as inferred from labels and titles.

???

In order to understand how our visual system perceives statistical charts, we must first consider the complexity of the graphic and how viewers are interacting with the data and information being displayed. Pattern recognition requires the viewer to encode graphic patterns while interpretive processes operate on those patterns to construct meaning. Integrative processes then relate the meanings to the contextual scenario as inferred from labels and titles. We will see how these three levels of task complexity relate to the research objectives of our study.

---
class:primary
# Research objectives

**Big Idea:** Are there benefits to displaying exponentially increasing data on a log scale rather than a linear scale?

1. Perception through Lineups `r fa_i("chart-line")` `r fa_i("chart-line")` `r fa_i("chart-bar")`

    - Test an individual's ability to perceptually differentiate exponentially increasing data with differing rates of change on both the linear and log scale.
    
2. Prediction with You Draw It `r fa_i("pen")`
    
    - Tests an individual's ability to make predictions for exponentially increasing data.
        
3. Estimation by Numerical Translation `r fa_i("ruler")`

    - Tests an individual's ability to translate a graph of exponentially increasing data into real value quantities.
    
???
In this research, we conducted a series of three graphical studies to evaluate the impact displaying data on the log scale has on human perception of exponentially increasing trends compared to displaying data on the linear scale. Each study was related to a different graphical task, each requiring a different level of interaction and cognitive use of the data being presented. 

1. The first experiment evaluated whether our ability to perceptually notice differences in exponentially increasing trends is impacted by the choice of scale. These perceptual differences are identified through pattern recognition.
2. The second study tested an individuals ability to make predictions for exponentially increasing data and required integrative processes by operate on the patterns to construct meaning.
3. The last and third study tested an individual's ability to translate a graph of exponentially increasing data into real value quantitites and extend these estmiates by making comparisons.

Combined, the three studies provide a comprehensive evaluation of the impact of displaying exponentially increasing data on a log scale as it relates to perception, prediction, and estimation. The results of these studies help us make recommendations and provide guidelines for the use of log scales.

---
class:primary
# Prolific data collection

+ About 300 participants were recruited via Prolific in March 2022.
+ The series of graphical tests were conducted through an RShiny application found [here](https://shiny.srvanderplas.com/perception-of-statistical-graphics/).


.center[
```{r, out.width = "100%"}
knitr::include_graphics("images/final-study-app-screenshot.png")
```
]

???
Participant recruitment and study deployment were conducted via Prolific, a crowd sourcing website, in March 2022. Participants were provided a link to an R Shiny application that asked them demographic information and then guided them through all three studies. For the final data collection, we collected data for about 300 participants for each study; this was the final data set used for analysis in my research.

---
class:inverse
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
.center[
# Perception through Lineups
]

???
I previously presented development processes and pilot study results for the first two chapters so I am going to briefly share a high level overview of the study and final data set results for these.

---
class:primary
# Lineup experimental task 

Study Participant Prompt: *Which plot is most different?*

.center[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/linear-lineup-example.png", alt = " ", other=list(width="45%"))
i2 <- img_modal(src = "images/log-lineup-example.png", alt = " ", other=list(width="45%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i2, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9],
  str_split(i2, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]

???
We used statistical lineups to test participants perception of exponentially increasing data. 'Lineups' are named after the 'police lineup' of criminal investigations where witnesses are asked to identify the criminal from a set of individuals. Similarly, a statistical lineup is a plot consisting of smaller panels where the viewer is asked to identify the panel containing the real data from among a set of decoy null plots. 

Here we see an example of statistical lineups as shown in the first study. Notice how it is much easier to pick out panel 13 as being most different when displayed on the log scale (right) than on the linear scale (left).

---
class:primary
# Lineup study design

.pull-left[
**Curvature:**
+ High Curvature
+ Medium  Curvature
+ Low Curvature
].pull-right[

```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/curvature-combination-example-1.png", alt = " ", other=list(width="100%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]
**Treatment Design:** Target Panel gets model A and Null Panels get model B

$3!\cdot 2!= 6$ curvature combinations
 
$\times 2$ lineup data sets per combination $=$ **12 test data sets**

$\times 2$ scales (log & linear) $=$ **24 different lineup plots**

**Experimental Design:** 12 lineup plots per participant

$6$ test parameter combinations per participant $\times 2$ scales $= 12$ test lineups

???

We used a 'goldilocks' type of approach to select coefficients related to three levels of curvature (low, medium, and high) for our data simulation. The lineups were then created by looking at combinations of each of these curvature levels where the data in the target panel was simulated with equation A and the data in the null panels were simulated with equation B for a total of 6 curvature combinations. We simulated 2 replicate data sets of each curvature combinations and each data set was plotted on botht he log and linear scales for a total of 24 different lineup plots to select from. Each participant ended up evaluating 12 lineup plots and ideally saw one of each of the 6 curvature combinations on both scales.

---
class:primary
# Generalized Linear Mixed Model

Define $Y_{ijkl}$ to be the event that participant $l$ correctly identifies the target plot for data set $k$ with curvature $j$ plotted on scale $i$.

$$\text{logit }P(Y_{ijk}) = \eta + \delta_i + \gamma_j + \delta \gamma_{ij} + s_l + d_k$$
where
- $\eta$ is the beaseline average probability of selecting the target plot. 
- $\delta_i$ is the effect of the log/linear scale.
- $\gamma_j$ is the effect of the curvature combination.
- $\delta\gamma_{ij}$is the two-way interaction effect of the scale and curvature.
- $s_l \sim N(0,\sigma^2_\text{participant})$, random effect for participant characteristics.
- $d_k \sim N(0,\sigma^2_{\text{data}})$, random effect for data specific characteristics.

We assume that random effects for data set and participant are independent.

???

Each lineup plot evaluated was assigned a value based on the participant response (correct = 1, not correct = 0). The binary response was analyzed using generalized linear mixed model following a binomial distribution with a logit link function. Here we account for the participant and data specific characteristics with random effects.

---
class:primary
# Lineup results

.center[
```{r, out.width = "90%"}
knitr::include_graphics("images/odds-ratio-plot-1.png")
```
]

???
Estimated (log) odds ratio of successfully identifying the target panel on the log scale compared to the linear scale. The y-axis indicates the the model parameters used to simulate the null plots with the target plot model parameter selection designated by shape and shade of green. The thumbnail figures on the right display the curvature combination as shown previously on both scales (linear - left, log - right).

The results indicated the choice of scale changes the contextual appearance of the data leading to slight perceptual advantages for both scales depending on the curvatures of the trend lines being compared.

---
class:inverse
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
.center[
# Prediction through 'You Draw It'
]

???
The second study evaluated participants ability to make forecast predictions of exponentially increasing data.

---
class:primary
# 'You Draw It' experimental task

Study Participant Prompt: *Use your mouse to fill in the trend in the yellow box region.*

.center[
```{r, out.width = "45%"}
knitr::include_graphics("images/exponential_example.gif")
```
]

???

In 2015, the New York Times introduced an interactive feature, called ‘You Draw It’, where readers input their own assumptions about various metrics and compare how these assumptions relate to reality. The Times team utilizes Data Driven Documents (D3) that allows readers to predict these metrics through the use of drawing a line on their computer screen with their mouse. We adapted this feature as a way to measure the patterns we see in data and compare intuitive visual model fitting and statistical model fitting. In the study, participants were shown a series of 'You Draw It' interactive task plots and asked to "Use your mouse to fill in the trend in the yellow box region." The yellow box region moves along as the participant draws their trend-line until the yellow region disappears, providing a visual cue for the task.

--

A sub-study validated a new method, 'You Draw It', as a tool for graphical testing statistical graphics and introduced an appropriate statistical analysis method for comparing visually fitted trend lines to statistical regression results [(Eye Fitting Straight Lines in the Modern Era)](https://earobinson95.github.io/Eye-Fitting-Straight-Lines-in-the-Modern-Era/Eye-Fitting-Straight-Lines-in-the-Modern-Era.pdf).

???


A sub-study validated a new method, 'You Draw It', as a tool for graphical testing statistical graphics and introduced an appropriate statistical analysis method for comparing visually fitted trend lines to statistical regression results.

---
class:primary 
# Treatment design

.pull-left[

Data were simulated based on a one-parameter exponential model: $N = 30$ points $(x_i,y_i), i = 1,...,N$ where 
$$y_i = e^{\beta x_i + e_i}$$
with $e_i \sim N(0,\sigma^2)$.

2 x 2 x 2 factorial:
+ **growth rate:** low and high.
+ **points truncated:** $50\%$ and $75\%$ of the domain.
+ **scale:** log and linear.

].pull-right[
.center[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/low-10-linear.png", alt = "Low Growth Rate, 50% Truncation, Linear Scale", other=list(width="30%"))
i2 <- img_modal(src = "images/low-10-log.png", alt = "Low Growth Rate, 50% Truncation, Log Scale", other=list(width="30%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i2, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9],
  str_split(i2, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```

```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/low-15-linear.png", alt = "Low Growth Rate, 75% Truncation, Linear Scale", other=list(width="30%"))
i2 <- img_modal(src = "images/low-15-log.png", alt = "Low Growth Rate, 75% Truncation, Log Scale", other=list(width="30%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i2, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9],
  str_split(i2, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```

```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/high-10-linear.png", alt = "High Growth Rate, 50% Truncation, Linear Scale", other=list(width="30%"))
i2 <- img_modal(src = "images/high-10-log.png", alt = "High Growth Rate, 50% Truncation, Log Scale", other=list(width="30%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i2, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9],
  str_split(i2, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```

```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/high-15-linear.png", alt = "High Growth Rate, 75% Truncation, Linear Scale", other=list(width="30%"))
i2 <- img_modal(src = "images/high-15-log.png", alt = "High Growth Rate, 75% Truncation, Log Scale", other=list(width="30%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i2, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9],
  str_split(i2, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]]

???
For this study, data were simulated based on a one-parameter exponential model. We designed a 2x2x2 factorial treatment design where we are looking at the effect of growth rate, having the aid of points, and of course the effect of scale. This creates a total of 8 treatment combinations for 'You Draw It' plots in which participants were shown in random order.


---
class:primary 
# Feedback data

.pull-left[
For each participant, the final data set used for analysis contains:
+ $x_{ijklm}$, $y_{ijklm,drawn}$, and $\hat y_{ijklm,NLS}$  

for:
+ growth rate $i = 1,2$,
+ point truncation $j = 1,2$,
+ scale $k = 1,2$,
+ participant  $l = 1,...N_{participant}$, and 
+ $x_{ijklm}$ value $m = 1, ...,4 x_{max} + 1$. 

Vertical residuals between the drawn and fitted values were calculated as: 
+ $e_{ijklm,NLS} = y_{ijklm,drawn} - \hat y_{ijklm,NLS}$.

].pull-right[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/exponential-yloess-spaghetti-plot-1.png", alt = " ", other=list(width="100%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]

???
Out of the study, we save the participant feedback data to a data base for analysis. Here we see a spaghetti plots of results. Participants drawn lines on the linear scale are shown in blue and the log scale are shown in orange. Variability in the statistically fitted regression lines occurred due to a unique data set being simulated for each individual; the gray band shows the range fitted values from the statistically fitted regression lines. Here we can see a strong underestimation on the linear scale (blue lines).

---
class:primary 
# Generalized Additive Mixed Model

Fit separate for each growth rate $i=1,2$, the GAMM equation for residuals is given by:
\begin{equation}
e_{ijklm,nls} = \tau_{ijk} + s_{ijk}(x_{ijklm}) + p_{l} + s_{l}(x_{ijklm})
\end{equation}

where

+ $e_{ijklm,NLS}$ is the residual between the drawn y-value and fitted y-value for the $l^{th}$ participant, $m^{th}$ increment, and $ijk^{th}$ treatment combination 
+ $\tau_{ijk}$ is the intercept for the $i^{th}$ growth rate, $j^{th}$ point truncation, and $k^{th}$ scale treatment combination
+ $s_{ijk}$ is the smoothing spline for the $ijk^{th}$ treatment combination
+ $x_{ijklm}$ is the x-value for the $l^{th}$ participant, $m^{th}$ increment, and $ijk^{th}$ treatment combination 
+ $p_{l} \sim N(0, \sigma^2_{participant})$ is the error due to the $l^{th}$ participant's characteristics 
+ $s_{l}$ is the random smoothing spline for the $l^{th}$ participant. 

???

Allowing for flexibility, the bam function in the mgcv package is used to fit a GAMM to estimate trends of vertical residuals from the participant drawn line in relation to the NLS fitted values. 

---
class:primary
# GAMM results

.center[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/exponential-prediction-gamm-preds-2.png", alt = " ", other=list(width="64%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```

```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/exponential-prediction-gamm-preds-3.png", alt = " ", other=list(width="64%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]

???
The results from the analysis showed a clear underestimation of forecasting trends with high exponential growth rates when participants were asked to make predictions on the linear scale.

---
class:inverse
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
.center[
# Numerical Translation and Estimation
]

---
class:primary
# Integrative processes

**Graph Comprehension**

The three behaviors related to graph comprehension involve `r Citep(bib[[c("curcio1987comprehension", "friel2001making", "glazer2011challenges", "jolliffe1991assessment", "wood1968objectives")]])`.

1. literal reading of the data (elementary level)
2. reading between the data (intermediate level)
3. reading beyond the data (advanced level).

**Estimation Biases**

+ Anchoring `r Citep(bib[[c("tan1990processing")]])` and rounding to multiples of five or ten `r Citep(bib[[c("myers1954accuracy")]])` arise in open-ended estimation tasks.
+ Scale and axis labels are other critical factors in estimation accuracy `r Citep(bib[[c("dunham1991learning", "beeby1973well", "leinhardt1990functions")]])`.  

???

Integrative processes requires viewers to translate the visual features into conceptual relations by interpreting titles, labels, and scales.

An important consideration in understanding graph comprehension is the
questions being asked of the viewer (Graesser, Swamer, Baggett, & Sell, 2014). 

Anchoring bias refers to an individual using easily
observed visual cues such as grid lines or “anchors” when extracting information
such as the x or y value on a chart (Tan, 1994 ; Godlonton, Hernandez, & Murphy,
2018)

Beeby & Taylor (1973) found that when asked to read data from line graphs, viewers consistently misread the y-axis scale; when alternate grid lines were labeled, the unlabeled grid lines were read as halves. 

The choice of scale can change the shape of a graph, thus creating a conceptual
demand for the viewer when constructing a mental image of the graph (Leinhardt,
Zaslavsky, & Stein, 1990)

---
class:primary
# Scenarios

.pull-left[
**Tribble scenario** 

Hi, we’re Tribbles! We were taken from our native planet, Iota Germinorum IV, and brought abroad Starfleet in stardate 4500. A Starfleet scientist, Edward Larkin, genetically engineered us to increase our reproductive rate in an attempt to solve a planetary food shortage. The Tribble population on Starfleet over the next 50 Stardates (equivalent to 1 week universe time) is illustrated in the graph. We need your help answering a few questions regarding the population of Tribbles.

].pull-right[

**Ewok scenario**

Hi, we’re Ewoks! We are native to the forest moon of Endor. After the Galactic Civil War, some Ewoks traveled offworld to help Rebel veterans as ’therapy Ewoks’ and began to repopulate. The Ewok population After the Battle of Yavin (ABY) is illustrated in the graph. We need your help answering a few questions regarding the population of Ewoks offworld.


]

*Fictional illustrations of the figures were modified from artwork
by Allison Horst (2021) and included on the main page for each scenario.*

---
class:primary
# Questioning

.center[
```{r, out.width = "65%"}
estimation_questions <- read_csv("data/estimation-questions.csv")
estimation_questions %>%
  filter(q_id != "scenario") %>%
  pivot_wider(id_cols = "q_id",
              names_from = "creature",
              values_from = "qtext") %>%
  mutate(q_id = c("Open Ended", "Elementary Q1", "Elementary Q2", "Intermediate Q1", "Intermediate Q2", "Intermediate Q3")) %>%
  kableExtra::kable("html", booktabs = T, col.names = c("Question type", "Tribble scenario", "Ewok scenario"))  %>%
  kableExtra::column_spec(2:3, width = "16em")
```
]

---
class:primary
# Data and plot generation

.pull-left[

Two unique data sets were simulated based on a three parameter exponential model with multiplicative errors:

$y_i=\alpha e^{\beta x_i + \epsilon_i} + \theta$ with $\epsilon_i \sim N(0, \sigma^2)$

for 

+ $x_i \in [0:50]$, 
+ $\alpha = 130$,
+ $\beta = 0.12$,
+ $\theta = 50$, and
+ $\sigma = 1.5$.

].pull-right[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/estimation-simulated-data-1.png", other=list(width="100%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]

The time unit labels on the x-axis reflected 0 to 50 ABY (After Battle of Yavin) for the Ewok scenario and were adjusted to 4500 to 4550 Stardates for the Tribble Scenario to align with the associated popular media depiction of each figure.

???

The time unit labels on the x-axis reflected 0 to 50 ABY (After Battle of Yavin) for the Ewok scenario and were adjusted to 4500 to 4550 Stardates for the Tribble Scenario to align with the associated popular media depiction of each figure as well as disguise the use of the same underlying data simulation model and estimation questions across both scenarios.

---
class:primary
# Study design

+ Participants were shown two examples with associated sketches (available throghout study).

+ The **scale** of the graphic and **data set** displayed was randomly assigned to scenarios for each individual.

+ The order in which the participant saw the scenario, scale, and data set combination was randomly selected.

+ Questioning: 

    + participants were first asked an open ended question
    + followed by a random order of two elementary level questions and three intermediate level questions.
    
---
class:primary
# Estimation strategy

.pull-left[
.center[
```{r, out.width = "100%"}
knitr::include_graphics("images/estimation-scratchwork-app.png")
```
]
].pull-right[
We recorded the inputted and evaluated calculations and scratch work of each participant in order to better understand participant strategies for estimation.
]

???
For instance, a participant may have seen a scatter plot of data set two
displayed on the linear scale paired with the Ewok scenario text and a scatter plot
of data set one displayed on the log scale paired with the Tribble scenario text. The
order of the two scenarios and their assigned data set and scale was randomly
assigned to each individual.

Participants were shown the graphic of both data sets on either the linear or log
scale with labels adjusted to reflect the associated scenario context and scale.

---
class:primary
# Open ended 

*"Between year 30 and 40, how does the population of [creatures] change?"*

.center[
```{r, out.width = "55%"}
knitr::include_graphics("images/estimation-word-cloud-1.png")
```
]

---
class:primary
# Estimation of population
### Elementary Q1

*"What is the population in year 10?"* 

.pull-left[

```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/qe1-sketch.png", other=list(width="100%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```

].pull-right[

```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/qe1-density-plot-10-all-1.png", other=list(width="100%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]

---
class:primary
# Estimation of population
### First level estimates

.pull-left[

```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/qi1-sketch.png", other=list(width="100%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```

].pull-right[
.center[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/spaghetti-dataset1-1.png", other=list(width="85%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```

```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/spaghetti-dataset2-1.png", other=list(width="85%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]]

---
class:primary
# Estimation of population
### Scratchwork

Participant calculations and scratch work provides support that participants equated halfway spatially as halfway numerically.

.pull-left[
2048 − 1024 = 1024

1024/2 = 512

512 + 1024 = 1536
].pull-right[
32768 − 16384 = 16384

32768 − 16384 = 16384

16384 ∗ 2 = 32768

16384/2 = 8192

8192 + 16384 = 24576.
]

---
class:primary
# Estimation of time
### Elementary Q2

*"In what year does the population reach 4,000?"*

.pull-left[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/qe2-sketch.png", other=list(width="100%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
].pull-right[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/qe2-density-plot-1.png", other=list(width="100%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]

---
class:primary
# Additive increase in population
### Intermediate Q1

*From 20 to 40, the population increases by ____ [creatures].*

.pull-left[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/qi1-density-1-2.png", other=list(width="100%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
].pull-right[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/qi1-density-2-2.png", other=list(width="100%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]

---
class:primary
# Multiplicative change in population
### Intermediate Q2

*How many times more [creatures] are there in 40 than in 20?*

.pull-left[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/qi2-sketch.png", other=list(width="100%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
].pull-right[

```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/qi2-density-1.png", other=list(width="100%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]

---
class:primary
# Misunderstanding of log logic
### Misinterpretation and miscalculations in Intermediate Q1 and Q2

.pull-left[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/qi2-plots-1.png", alt = 'Observed estimated change in population for Intermediate Q2.', other=list(width="90%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
].pull-right[

**Additive Increase Incorrect Logic**

2048 − 1024 = 1024

1024 + 512 = 1536

16384 − 1536 = 14848

14848/1536 = 9.67.

**Multiplicative Change Incorrect Logic**

16384 − 1536 = 14848

]

Further investigation is necessary to determine if the misunderstanding occurs due to the ambiguity of language or scale.

---
class:primary
# Time until population doubles
### Intermediate Q3
*How long does it take for the population in year 10 to double?*

.pull-left[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/qi3-sketch.png", other=list(width="100%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
].pull-right[

```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/qi3-density-1.png", other=list(width="100%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]

---
class:primary
# Main take-aways

+ Understanding log logic is difficult.

+ Accuracy greatly depends on the location of the value being estimated in relation to the magnitude.

+ Strong anchoring and rounding effects.

  + Participants were resistance to estimate between grid lines on the log scale.
  
  + Inaccurate representation of equating spatial distance to quantitative difference. 
  
+  Inaccurate first level estimations can lead to consequences in estimations which require participants to make comparisons between two points.

+ Estimates were subjective to the simulated data set.

???

+ This is also supported in following participants estimation strategies for making first level estimates in Intermediate Q3 rather than relying on their spatial awareness between grid lines on the log scale
+ For example, accuracy and variability of population estimates made on the linear scale improved as the year of interest increased and thus the magnitude of population increased, making the point more visible.
---
class:inverse
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
.center[
# Conclusion and Discussion
]

---
class:primary
# Conclusions

**Perception** `r fa_i("chart-line")` `r fa_i("chart-line")` `r fa_i("chart-bar")`

+ Perceptual differences result from the contextual appearance (depends on choice of scale) of the trends.

**Prediction** `r fa_i("pen")`

+ Clear underestimation of forecasting trends with high exponential growth rates when participants were asked to make predictions on the linear scale.


**Estimation** `r fa_i("ruler")`

+ Log logic is difficult and that we often misinterpret and miscalculate multiplicative reasoning.
+ Estimation accuracy for small magnitudes was improved by the use of the log scale, but sacrifices in accuracy on the log scale became apparent as magnitudes increased leading to advantages on the linear scale.


---
class:primary
# Overall Recommendations

`r fa_i("eye")` Perceptual advantages of the use of log scales due to the change in contextual appearance.

`r fa_i("brain")` Our understanding of log logic is flawed when translating the information into context. 

`r fa_i("list")` We recommend consideration of both user needs and graph specific tasks when presenting data on the log scale.

`r fa_i("exclamation")` Caution should be taken when interpretation of large magnitudes is required, but
advantages may appear when it is necessary to visually identify and interpret small
magnitudes on the chart. 

???
This research evaluated the use of log scales to display exponentially increasing
data from three different angles and levels of complexity: perception, prediction,
and estimation. Each study provided us insight into the advantages and
disadvantages of displaying exponentially increasing data on a log scale and in what
context each choice of scale might be more appropriate.

The studies conducted in this research relied on graphical tasks of varying
complexity in order to help us understand the perceptual and cognitive advantages
and disadvantages of displaying exponentially increasing data on the log scale. 

---
class:primary
# Future work

+ Potential follow-up studies:
    + Providing users the ability to interact with the graph with visual aids in order to better understand strategies of estimation.
    + Additional study which focuses on how we make decisions based on data displayed on a log scale in order to evaluate the effect of scale on risk adversity.

+ Expand the use of log scales to data which does not follow an exponential trend, but where log scales are otherwise appropriate.

+ Evaluate the implications of transforming or displaying the $x$-axis on a log scale.

+ More widespread use of comprehensive graphical studies conducted on the same type of data and plot.

???

+ This research stands as a model for conducting an extensive series of graphical tasks on the same type of data and plot in order to gain a comprehensive understanding of both the perceptual and cognitive implications of the design choices.

---
class:primary
# References
<font size="1">
```{r, print_refs1, results='asis', echo=FALSE, warning=FALSE, message=FALSE}
print(bib[[c("vonbergmann_2021", "dehaene2008log", "siegler_numerical_2017", "varshney_why_2013", "jones_generalized_1979", "mackinnon_feedback_1991", "wagenaar_misperception_1975", "curcio1987comprehension", "friel2001making", "glazer2011challenges", "jolliffe1991assessment", "wood1968objectives", "wickham2013graphical", "andrews_2022", "tufte1985visual", "dongarra1997top500", "villa_2022", "andrews_2022")]], 
      .opts = list(check.entries = FALSE, style = "html", bib.style = "authoryear")
      )
```
</font>

---
class:primary
# Acknowledgements

**Advisors**

+ Dr. Susan VanderPlas
+ Dr. Reka Howard

**Committee Members**

+ Dr. Erin Blankenship
+ Dr. Heather Akin

**Other**
+ Mentors during graduate school
+ Professors from Winona State University
+ Graduate school friends and peers
+ Family

---
class:inverse
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
.center[
# Questions?
<!-- <br> -->
<!-- <br> -->
<!-- `r fa("envelope", fill = "white")` **emily.robinson@huskers.unl.edu** -->
<!-- `r fa("home", fill = "white")` **www.emilyarobinson.com** -->
<!-- `r fa("github", fill = "white")` **earobinson95** -->
]
